{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We're going to play with very simple layer ANNs. Even with just one layer we'll be able to do some fun stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our activation function, just a simple sigmoidal curve called the logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_func(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the logistic function by plotting in in the range of -10 to 10 using this handy built-in numpy function *linspace*. This function takes the lower bound, the upper bound, and the number of values, and returns a *linearly spaced* vector including the lower and upper bounds. **Neat!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.          -8.94736842  -7.89473684  -6.84210526  -5.78947368\n",
      "  -4.73684211  -3.68421053  -2.63157895  -1.57894737  -0.52631579\n",
      "   0.52631579   1.57894737   2.63157895   3.68421053   4.73684211\n",
      "   5.78947368   6.84210526   7.89473684   8.94736842  10.        ]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-10, 10,20)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113231e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now plot it!\n",
    "pyplot.plot(x, logistic_func(x))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to make a simple network that generates the following truth table\n",
    "\n",
    "| Input 1 | Output |\n",
    "|---------|--------|\n",
    "| 0       | 0      |\n",
    "| 1       | 1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993307149076\n"
     ]
    }
   ],
   "source": [
    "# Since we're only using one value, our input\n",
    "# is a single value\n",
    "input_vector = np.array([1])\n",
    "input_weights = np.array([5])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "\n",
    "# Now apply our activation function to the \n",
    "# sum of the inputs*weights vector\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Since we're only using one value, our input\n",
    "# is a single value\n",
    "input_vector = np.array([0])\n",
    "input_weights = np.array([5])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm, we're going to have a hard time multipling 0 by something to get a lower value...\n",
    "To fix this problem, we use something called a **bias node**. Basically, we give the neural network a constant value to use for situations exactly like this. This is typically set at 1, though -1 is also a common choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0474258731776\n"
     ]
    }
   ],
   "source": [
    "# Now we're passing in a bias node with value set to 1\n",
    "# so we'll also have to give it's synapse a weight!\n",
    "input_vector = np.array([0, 1])\n",
    "\n",
    "# I just picked a few big values that will pull the \n",
    "# logistic function close to either 0 or 1 depending on\n",
    "# the value of the input. \n",
    "input_weights = np.array([6, -3])\n",
    "\n",
    "# because we're using numpy arrays, when we do multiplication\n",
    "# it will automatically perform it element-by-element\n",
    "input_x_weights = input_vector * input_weights\n",
    "neuron_sum = sum(input_x_weights)\n",
    "activation = logistic_func(neuron_sum)\n",
    "\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can shorten this a lot using some nice numpy built in functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0474258731776\n"
     ]
    }
   ],
   "source": [
    "input_vector = np.array([0, 1])\n",
    "input_weights = np.array([6, -3])\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "# numpy's dot function computes the inner product \n",
    "# e.g., [a,b].[c,d] = [a*c + b*d]\n",
    "activation = logistic_func(np.dot(input_vector, input_weights))\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Try your hand at choosing weights for a network that can compute this function\n",
    "\n",
    "| Input 1 | Output |\n",
    "|---------|--------|\n",
    "| 0       | 1      |\n",
    "| 1       | 0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Let's make it a bit more complex and add a second input!\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 1      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You should make sure your weights handle all the possible binary inputs we can give this function -- like the following input vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector = np.array([0, 0, 1])\n",
    "input_vector = np.array([0, 1, 1])\n",
    "input_vector = np.array([1, 0, 1])\n",
    "input_vector = np.array([1, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What would you have to do if we wanted to have more than one output?\n",
    "Let's try to replicate the following truth table (i.e., mirror the bits)\n",
    "\n",
    "| Input 1 | Input 2 | Output 1 | Output 2 |\n",
    "|---------|---------|----------|----------|\n",
    "| 0       | 0       | 0        | 0        |\n",
    "| 0       | 1       | 1        | 0        |\n",
    "| 1       | 0       | 0        | 1        |\n",
    "| 1       | 1       | 1        | 1        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Because now each input node has more than one output node to connect to, we'll need more weights. \n",
    "\n",
    "#### We can store these weights as a matrix with 3 rows (one for each input plus the bias) and 2 columsn (one for each output). Thus, each value is a weight from the row's input node to the column's output node. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.881  0.881]\n"
     ]
    }
   ],
   "source": [
    "input_vector = np.array([1, 0, 1])\n",
    "\n",
    "#TODO: You'll have to change these weights! \n",
    "input_weights = np.array( [[1, 1],\n",
    "                           [1, 1],\n",
    "                           [1, 1]])\n",
    "\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "# we get to take advantage of more numpy fancyness here,\n",
    "# when np.dot is given a matrix, it performs matrix multiplication!\n",
    "activation = logistic_func(np.dot(input_vector, input_weights))\n",
    "print(np.round(activation, decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You'll want to check all the possible combinations of 2-bit inputs again, like you did in Question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. If you're feeling brave, try your hand at this one.\n",
    "Hint: It's not as simple as it looks... You'll need more **layers** for this one!\n",
    "\n",
    "| Input 1 | Input 2 | Output |\n",
    "|---------|---------|--------|\n",
    "| 0       | 0       | 0      |\n",
    "| 0       | 1       | 1      |\n",
    "| 1       | 0       | 1      |\n",
    "| 1       | 1       | 0      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
